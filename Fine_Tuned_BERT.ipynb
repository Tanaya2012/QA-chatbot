{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tanaya2012/QA-chatbot/blob/main/Fine_Tuned_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tuning BERT for better results"
      ],
      "metadata": {
        "id": "BokPE2qZMwU_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook demonstrates the process of fine-tuning the BERT model using a dataset generated from a pre-trained question generation model. The notebook utilizes the BERT model to train on the generated dataset, which consists of questions, answers, and corresponding context. \n",
        "\n",
        "The notebook includes steps to preprocess the dataset, such as tokenization and encoding. It then proceeds to fine-tune the BERT model on the preprocessed dataset, adjusting the model's weights and parameters to optimize performance for the specific question generation task.\n",
        "\n",
        "Throughout the notebook, various evaluation metrics and techniques may be employed to assess the performance of the fine-tuned BERT model. The notebook provides code examples and explanations, allowing users to understand and reproduce the fine-tuning process for BERT in the context of question generation tasks."
      ],
      "metadata": {
        "id": "emv-m3bQLXpw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_d7JJtoKBwX",
        "outputId": "7e8c5251-6757-476c-c3c5-0fe300a19fc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VMNXGgWQeF8Q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, Trainer, TrainingArguments, PreTrainedModel, PreTrainedTokenizerFast, AdamW\n",
        "from pathlib import Path\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the generated dataset"
      ],
      "metadata": {
        "id": "RY53V1psMMld"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hFjOSiqYKJqP",
        "outputId": "34516776-33c8-471b-e040-558274e7a7e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                             answer  \\\n",
              "0           0             <pad> emphysema and chronic bronchitis   \n",
              "1           1                                airflow obstruction   \n",
              "2           0                                         <pad> copd   \n",
              "3           0  <pad> to reduce activity limitations among adu...   \n",
              "4           0                                         <pad> 2013   \n",
              "\n",
              "                                            question  \\\n",
              "0  What are the symptoms of chronic obstructive p...   \n",
              "1  What is the cause of chronic obstructive pulmo...   \n",
              "2  What is an important contributor to mortality ...   \n",
              "3           What is the goal of healthy people 2020?   \n",
              "4  In what year did cdc analyze data from the beh...   \n",
              "\n",
              "                                                text  \n",
              "0  chronic obstructive pulmonary disease copd is ...  \n",
              "1  chronic obstructive pulmonary disease copd is ...  \n",
              "2  copd is an important contributor to mortality ...  \n",
              "3  healthy people 2020 has several copdrelated ob...  \n",
              "4  to assess the statelevel prevalence of copd an...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d49af43d-f39d-49fb-9777-bccf309682b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>answer</th>\n",
              "      <th>question</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>&lt;pad&gt; emphysema and chronic bronchitis</td>\n",
              "      <td>What are the symptoms of chronic obstructive p...</td>\n",
              "      <td>chronic obstructive pulmonary disease copd is ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>airflow obstruction</td>\n",
              "      <td>What is the cause of chronic obstructive pulmo...</td>\n",
              "      <td>chronic obstructive pulmonary disease copd is ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>&lt;pad&gt; copd</td>\n",
              "      <td>What is an important contributor to mortality ...</td>\n",
              "      <td>copd is an important contributor to mortality ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>&lt;pad&gt; to reduce activity limitations among adu...</td>\n",
              "      <td>What is the goal of healthy people 2020?</td>\n",
              "      <td>healthy people 2020 has several copdrelated ob...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>&lt;pad&gt; 2013</td>\n",
              "      <td>In what year did cdc analyze data from the beh...</td>\n",
              "      <td>to assess the statelevel prevalence of copd an...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d49af43d-f39d-49fb-9777-bccf309682b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d49af43d-f39d-49fb-9777-bccf309682b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d49af43d-f39d-49fb-9777-bccf309682b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/df_bert_train.csv\")\n",
        "pdf_text = Path('/content/drive/MyDrive/cleaned_sentences.txt').read_text()\n",
        "cleaned_sentences_with_stopwords = pdf_text.split('\\n')\n",
        "clean_text = pdf_text.replace('\\n', ' ')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_questions = ['When did the GARDASIL 9 recommendations change?',\n",
        "'What were the past 3 recommendation changes for GARDASIL 9?',\n",
        "'Is GARDASIL 9 recommended for Adults?',\n",
        "'Does the ACIP recommend one dose GARDASIL 9?']"
      ],
      "metadata": {
        "id": "sUHsifLNCS0R"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine Tuning"
      ],
      "metadata": {
        "id": "y3KnrHlIMdmL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet performs several tasks related to preparing a dataset for training a question answering model using BERT.\n",
        "\n",
        "First, it splits the questions, answers, and contexts into training and validation sets.\n",
        "\n",
        "Next, it specifies the choice of a pre-trained model and tokenizer, specifically using the 'distilbert-base-uncased-distilled-squad' model.\n",
        "\n",
        "Then, it prepares the dataset by encoding the training and validation contexts and questions using the tokenizer, incorporating truncation and padding.\n",
        "\n",
        "The code proceeds to add the start and end positions of the answer within the input, by finding the answer tokens' occurrence in the encoded input.\n",
        "\n",
        "Afterward, a custom dataset class called 'QADataset' is created, which handles the data in a suitable format for training. It converts the encodings into tensors and defines the length of the dataset.\n",
        "\n",
        "Finally, the training and validation datasets are instantiated using the 'QADataset' class, using the respective encodings.\n",
        "\n",
        "Overall, this code segment organizes the data into appropriate structures, prepares the inputs for BERT, and sets up custom dataset classes for training and validation datasets."
      ],
      "metadata": {
        "id": "6SH5U-GSMQP3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SK8uSznpdw1n"
      },
      "outputs": [],
      "source": [
        "questions = data.question.tolist()\n",
        "answers = data.answer.tolist()\n",
        "contexts = data.text.tolist()\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "split_index = int(0.8 * len(questions))\n",
        "train_questions, val_questions = questions[:split_index], questions[split_index:]\n",
        "train_answers, val_answers = answers[:split_index], answers[split_index:]\n",
        "train_contexts, val_contexts = contexts[:split_index], contexts[split_index:]\n",
        "\n",
        "# Choose a pre-trained model and tokenizer\n",
        "model_name = 'distilbert-base-uncased-distilled-squad'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "\n",
        "# Prepare the dataset using the tokenizer\n",
        "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)\n",
        "\n",
        "# Add start_positions and end_positions to the dataset\n",
        "def add_token_positions(encodings, answers):\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "    for i in range(len(answers)):\n",
        "        # Get the answer tokens\n",
        "        answer_tokens = tokenizer.encode(answers[i], add_special_tokens=False)\n",
        "        \n",
        "        # Find the first occurrence of the answer tokens in the encoded input\n",
        "        for j in range(len(encodings.input_ids[i]) - len(answer_tokens) + 1):\n",
        "            if encodings.input_ids[i][j:j + len(answer_tokens)] == answer_tokens:\n",
        "                ans_start = j\n",
        "                ans_end = j + len(answer_tokens) - 1\n",
        "                break\n",
        "        else:\n",
        "            # If the answer is not found, set the start and end positions to 0\n",
        "            ans_start = 0\n",
        "            ans_end = 0\n",
        "\n",
        "        start_positions.append(ans_start)\n",
        "        end_positions.append(ans_end)\n",
        "\n",
        "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "\n",
        "add_token_positions(train_encodings, train_answers)\n",
        "add_token_positions(val_encodings, val_answers)\n",
        "\n",
        "# Create a custom dataset class\n",
        "class QADataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "train_dataset = QADataset(train_encodings)\n",
        "val_dataset = QADataset(val_encodings)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall -y transformers accelerate\n",
        "# !pip install transformers accelerate"
      ],
      "metadata": {
        "id": "ebhZmOzD9SzL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet sets up training arguments and a Trainer object for fine-tuning the BERT model on the provided dataset. It defines parameters such as the output directory, number of training epochs, batch sizes, learning rate, and logging directory. The Trainer is instantiated with the model, training arguments, training, and evaluation datasets, along with a custom optimizer. The model is then fine-tuned using the trainer's `train()` method. Finally, the fine-tuned model and tokenizer are saved in the specified directory for future use."
      ],
      "metadata": {
        "id": "kAlTbaTuMrdv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "NT3CbRTngPT4",
        "outputId": "f3c759ce-b0da-4ba9-a110-ec1b8219712b"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='346' max='385' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [346/385 3:30:24 < 23:51, 0.03 it/s, Epoch 9.86/11]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='385' max='385' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [385/385 3:54:14, Epoch 11/11]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./FineTunedModel/tokenizer_config.json',\n",
              " './FineTunedModel/special_tokens_map.json',\n",
              " './FineTunedModel/vocab.txt',\n",
              " './FineTunedModel/added_tokens.json',\n",
              " './FineTunedModel/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Set up training arguments and the Trainer\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=11,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    logging_dir='./logs',\n",
        "    learning_rate=1e-4, # Custom learning rate\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    optimizers=(AdamW(model.parameters(), lr=1e-4), None), # Custom optimizer with the learning rate\n",
        ")\n",
        "\n",
        "# Fine-tune the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the fine-tuned model\n",
        "model.save_pretrained('./FineTunedModel')\n",
        "tokenizer.save_pretrained('./FineTunedModel')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "X_XR8B0WNHzt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet loads a fine-tuned question answering model and tokenizer from a specified directory. It defines a function called `get_answer` that takes the loaded model, tokenizer, question, and context as input. The function tokenizes the question and context, processes the inputs with the model, and obtains the start and end scores. It identifies the answer tokens and converts them back into a string format. If the answer is empty, the score is set to 0.0. The function returns the answer and corresponding score."
      ],
      "metadata": {
        "id": "W3A-rX-tNSkX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "YctLxZN2fx4K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feaa507d-6766-4cfc-9fb5-5be4e1f39db8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: ('', 0.0)\n"
          ]
        }
      ],
      "source": [
        "# Load the fine-tuned model and tokenizer\n",
        "model = AutoModelForQuestionAnswering.from_pretrained('./FineTunedModel')\n",
        "tokenizer = AutoTokenizer.from_pretrained('./FineTunedModel')\n",
        "\n",
        "def get_answer(model: PreTrainedModel, tokenizer: PreTrainedTokenizerFast, question: str, context: str = None) -> str:\n",
        "    \n",
        "    inputs = tokenizer(question, context, return_tensors='pt', max_length=512, truncation=True)\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    start_scores, end_scores = outputs.start_logits, outputs.end_logits\n",
        "    score = float(torch.max(start_scores))\n",
        "    start_index = torch.argmax(start_scores)\n",
        "    end_index = torch.argmax(end_scores)\n",
        "\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "    answer_tokens = tokens[start_index:end_index + 1]\n",
        "    answer_tokens = [token for token in answer_tokens if token not in tokenizer.all_special_tokens]\n",
        "    answer = tokenizer.convert_tokens_to_string(answer_tokens)\n",
        "\n",
        "    if answer == '':\n",
        "      score = 0.0\n",
        "\n",
        "    return answer, score\n",
        "\n",
        "question = \"When did the GARDASIL 9 recommendations change?\"\n",
        "answer = get_answer(model, tokenizer, question)\n",
        "print(\"Answer:\", answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Answer"
      ],
      "metadata": {
        "id": "Dy2Lvj_WSVc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for question in user_questions:\n",
        "  max_score = 0.0\n",
        "  final_ans = ''\n",
        "  for text in cleaned_sentences_with_stopwords:\n",
        "    ans, score = get_answer(model, tokenizer, question, text)\n",
        "    if score > max_score:\n",
        "      final_ans = ans\n",
        "      max_score = score \n",
        "  print('Question:', question)\n",
        "  print(\"final answer: \", final_ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tI3_5c4qH9Jm",
        "outputId": "984d683b-c543-4879-9f4c-79cc872cf3e3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: When did the GARDASIL 9 recommendations change?\n",
            "final answer:  july 1\n",
            "Question: What were the past 3 recommendation changes for GARDASIL 9?\n",
            "final answer:  costeffectiveness modeling\n",
            "Question: Is GARDASIL 9 recommended for Adults?\n",
            "final answer:  \n",
            "Question: Does the ACIP recommend one dose GARDASIL 9?\n",
            "final answer:  81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GsuSO-IjLFVQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "11jwTE9i7oaZnKVeh4rDWccI6OdJp4neQ",
      "authorship_tag": "ABX9TyP40WSbWKR7ncZuHHafP7ev",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}