{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tanaya2012/QA-chatbot/blob/main/similarity_method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook demonstrates the implementation of three basic techniques for a Question-Answering (QA) chatbot. The techniques utilized are Cosine Similarity search, and Word2Vec.\n",
        "\n",
        "1. Cosine Similarity search: This technique involves using a vector-based representation of the documents and computing the cosine similarity between the query and each document. It enables the chatbot to search for the most similar document or context to the given question and retrieve relevant answers based on the similarity scores.\n",
        "\n",
        "2. Word2Vec: Word2Vec is a widely used word embedding technique that represents words in a high-dimensional vector space. The notebook utilizes Word2Vec to capture semantic relationships between words and enhance the chatbot's understanding of the query and context. It allows the chatbot to find similar words or phrases and provide more accurate and contextually relevant answers.\n",
        "\n",
        "The notebook provides detailed explanations, code examples, and step-by-step instructions for implementing these techniques. It showcases how to integrate BERT, Cosine Similarity search, and Word2Vec into a QA chatbot system, enabling accurate and meaningful interactions with users."
      ],
      "metadata": {
        "id": "-glD7iCEQR3s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Collection"
      ],
      "metadata": {
        "id": "tHQhdHf5RBic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "text = Path('/content/drive/MyDrive/cleaned_sentences.txt').read_text()\n",
        "cleaned_sentences_with_stopwords = text.split('\\n')\n",
        "pdf_text = text.replace('/n', ' ')"
      ],
      "metadata": {
        "id": "x-VIieXNMK7f"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FAHBkY3mXnm0"
      },
      "outputs": [],
      "source": [
        "user_questions = ['When did the GARDASIL 9 recommendations change?',\n",
        "'What were the past 3 recommendation changes for GARDASIL 9?',\n",
        "'Is GARDASIL 9 recommended for Adults?',\n",
        "'Does the ACIP recommend one dose GARDASIL 9?']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_sentence(sentence, stopwords=False):\n",
        "  sentence = sentence.lower().strip()\n",
        "  sentence = re.sub(r'[^a-z0-9\\s]', '', sentence)\n",
        "  if stopwords:\n",
        "    sentence = remove_stopwords(sentence)\n",
        "  return sentence"
      ],
      "metadata": {
        "id": "w0oMfTRPMm7N"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OruRb8CjQsr4"
      },
      "source": [
        "# Cosine similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cosine similarity search is a technique used in a QA chatbot to find the most relevant answers based on the similarity between a query and a set of documents or contexts. It operates by representing the text data and queries as high-dimensional vectors and then calculating the cosine similarity between them.\n",
        "\n",
        "To compute cosine similarity, the angle between the query vector and each document vector is measured. A smaller angle indicates a higher similarity between the query and the document. Cosine similarity ranges from -1 to 1, with 1 representing identical vectors and -1 indicating completely opposite vectors.\n",
        "\n",
        "The cosine similarity scores are used to rank the documents or contexts in descending order. The document or context with the highest similarity score is considered the most relevant and is returned as the answer by the QA chatbot."
      ],
      "metadata": {
        "id": "zwsKiglmRTkL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mN1YSpmxvH5G"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "sentences = cleaned_sentences_with_stopwords\n",
        "sentence_words = [[word for word in document.split()]\n",
        "                  for document in sentences]\n",
        "\n",
        "from gensim import corpora\n",
        "dictionary = corpora.Dictionary(sentence_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CSffNmmKvM-_"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "bow_corpus = [dictionary.doc2bow(text) for text in sentence_words]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The given code defines a function named `retrieveAndPrintFAQAnswer` that retrieves the most relevant answer for a given question by comparing the question's embedding with a set of sentence embeddings. It iterates through the sentence embeddings, calculates the cosine similarity between the question embedding and each sentence embedding, and keeps track of the maximum similarity score. The index of the sentence with the highest similarity score is returned as the retrieved answer."
      ],
      "metadata": {
        "id": "G5ZcFKUWRpKa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Answer"
      ],
      "metadata": {
        "id": "k59UUOx6SdL_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMEfHJ3zvWMS",
        "outputId": "5b72d8c3-91fc-481d-a0ac-9d54113796fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question:  when did the gardasil 9 recommendations change\n",
            "Answer:  however specimen collection was delayed 2 days until trained ecdhd staff members visited the facility\n",
            "Question:  what were the past 3 recommendation changes for gardasil 9\n",
            "Answer:  however specimen collection was delayed 2 days until trained ecdhd staff members visited the facility\n",
            "Question:  is gardasil 9 recommended for adults\n",
            "Answer:  hpv vaccine is recommended for routine vaccination at age 11 or 12 years\n",
            "Question:  does the acip recommend one dose gardasil 9\n",
            "Answer:  however specimen collection was delayed 2 days until trained ecdhd staff members visited the facility\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import re \n",
        "\n",
        "def retrieveAndPrintFAQAnswer(question_embedding, sentence_embeddings, sentences):\n",
        "  max_sim = -1\n",
        "  index_sim = -1\n",
        "  for index, embedding in enumerate(sentence_embeddings[:-1]):\n",
        "    sim = cosine_similarity(embedding, question_embedding)[0][0]\n",
        "    # print(index, sim, sentences[index])\n",
        "    if sim > max_sim:\n",
        "      max_sim = sim\n",
        "      index_sim = index\n",
        "  \n",
        "  return index_sim\n",
        "\n",
        "for user_question in user_questions:\n",
        "  question = clean_sentence(user_question, stopwords=False)\n",
        "  question_embedding = dictionary.doc2bow(question.split())\n",
        "  index = retrieveAndPrintFAQAnswer(question_embedding, bow_corpus, sentences)  \n",
        "  print(\"Question: \", question)\n",
        "  print(\"Answer: \", sentences[index])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZjIlxgm0YY_"
      },
      "source": [
        "# Word2Vec\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2Vec is a popular word embedding model that represents words as dense vectors in a high-dimensional space, capturing semantic relationships. It learns these vector representations by training a neural network on large text corpora, enabling efficient computation of word similarities and semantic analogies."
      ],
      "metadata": {
        "id": "5zcTX_c2SOGJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dhiLBMexiFN",
        "outputId": "fd93658c-1e5b-4842-e0f4-003b25d09419"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=================================================-] 99.9% 1660.9/1662.8MB downloaded\n",
            "w2v Model Saved\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Word2Vec\n",
        "import gensim.downloader as api\n",
        "\n",
        "v2w_model = None\n",
        "try:\n",
        "  v2w_model = gensim.models.Keyedvectors.load('./w2vecmodel.mod')\n",
        "  print(\"w2v Model Successfully loaded\")\n",
        "except:\n",
        "  v2w_model = api.load('word2vec-google-news-300')\n",
        "  v2w_model.save(\"./w2vecmodel.mod\")\n",
        "  print(\"w2v Model Saved\")\n",
        "\n",
        "w2vec_embedding_size = len(v2w_model['pc'])  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The given code snippet defines two functions: `getWordVec` and `getPhraseEmbedding`.\n",
        "\n",
        "The `getWordVec` function takes a word and a word embedding model as inputs. It tries to retrieve the vector representation of the word from the embedding model. If the word is present in the model, the corresponding vector is returned. Otherwise, it returns a zero vector of the same length as the sample vector from the model.\n",
        "\n",
        "The `getPhraseEmbedding` function takes a phrase and an embedding model as inputs. It initializes a sample vector by obtaining the vector representation of the word \"computer\" from the model. It then iterates through each word in the input phrase, retrieves its vector representation using the `getWordVec` function, and accumulates the vectors. The resulting vector is divided by the total number of words in the phrase to obtain the average embedding. The function returns the average embedding as a reshaped 1D vector.\n",
        "\n",
        "These functions enable obtaining word vectors and computing the average embedding for a given phrase using the specified word embedding model. These embeddings can be utilized for various natural language processing tasks such as similarity comparison, clustering, or input representation in machine learning models."
      ],
      "metadata": {
        "id": "5Yg6w7NdR2GQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iIOr7h6IyH8w"
      },
      "outputs": [],
      "source": [
        "def getWordVec(word, model):\n",
        "  samp = model['pc']\n",
        "  vec = [0]*len(samp)\n",
        "  try:\n",
        "    vec = model[word]\n",
        "  except:\n",
        "    vec = [0]*len(samp)\n",
        "  return (vec)\n",
        "\n",
        "\n",
        "def getPhraseEmbedding(phrase, embeddingmodel):\n",
        "  samp = getWordVec('computer', embeddingmodel)\n",
        "  vec = numpy.array([0]*len(samp))\n",
        "  den = 0;\n",
        "  for word in phrase.split():\n",
        "    den = den+1\n",
        "    vec = vec+numpy.array(getWordVec(word, embeddingmodel))\n",
        "  return vec.reshape(1, -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Answer"
      ],
      "metadata": {
        "id": "b3tqUGQJSRtQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSiTIXZFyLBD",
        "outputId": "94388bf1-939b-4fac-ccb5-1a2bbcd566ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question:  when did the gardasil 9 recommendations change\n",
            "Answer:  two evidence to recommendations documents were developed   and presented along with proposed recommendations after a public comment period acip members voted unanimously to harmonize catchup vaccination recommendations across genders for all persons through age 26 years\n",
            "Question:  what were the past 3 recommendation changes for gardasil 9\n",
            "Answer:  all three vaccines have been approved for administration in a 3dose series at intervals of 0 1 or 2 and 6 months\n",
            "Question:  is gardasil 9 recommended for adults\n",
            "Answer:  catchup hpv vaccination is not recommended for all adults aged 26 years\n",
            "Question:  does the acip recommend one dose gardasil 9\n",
            "Answer:  the number of recommended doses is based on age at administration of the first dose\n"
          ]
        }
      ],
      "source": [
        "sent_embeddings = []\n",
        "for sent in sentences:\n",
        "  sent_embeddings.append(getPhraseEmbedding(sent, v2w_model))\n",
        "\n",
        "for user_question in user_questions:\n",
        "  question = clean_sentence(user_question, stopwords=False)\n",
        "  question_embedding = getPhraseEmbedding(question, v2w_model)\n",
        "  index = retrieveAndPrintFAQAnswer(question_embedding, sent_embeddings, cleaned_sentences_with_stopwords)\n",
        "  print(\"Question: \", question)\n",
        "  print(\"Answer: \", sentences[index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oLWWgDpCyUud"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "1m2IHS2MpzwkUZqFEIi2ABbnco1Rr4hJR",
      "authorship_tag": "ABX9TyPzyxBp/gbn26gZznMHjotE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}